{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "72920433",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a6016ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Load a COCO-pretrained YOLO11n model\n",
    "model = YOLO(\"yolo11n.pt\")\n",
    "# result=model.train(data='coco8.yaml',epochs=100,imgsz=640)\n",
    "\n",
    "# reuslts=model('download.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d3ea15c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Lưu mô hình đã huấn luyện\n",
    "model.save(\"trained_model.pt\")  # Lưu mô hình vào tệp 'trained_model.pt'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2345a6e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\download.jpg: 480x640 1 person, 2 buss, 58.2ms\n",
      "Speed: 4.3ms preprocess, 58.2ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Dự đoán trên một ảnh\n",
    "model2 = YOLO(\"yolo11n.pt\")\n",
    "results = model2('download.jpg')  # predict on an image\n",
    "\n",
    "for result in results:\n",
    "    boxes = result.boxes  # Boxes object for bounding box outputs\n",
    "    masks = result.masks  # Masks object for segmentation masks outputs\n",
    "    keypoints = result.keypoints  # Keypoints object for pose outputs\n",
    "    probs = result.probs  # Probs object for classification outputs\n",
    "    obb = result.obb  # Oriented boxes object for OBB outputs\n",
    "    result.show()  # display to screen\n",
    "    result.save(filename=\"result.jpg\")  # save to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85fbc53c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Dự đoán trên video\n",
    "model2 = YOLO(\"trained_model.pt\")\n",
    "results = model2('car-detection.mp4',save=True,show=True)  # predict on a video\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4beb0a1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "WARNING  inference results will accumulate in RAM unless `stream=True` is passed, causing potential out-of-memory\n",
      "errors for large sources or long-running streams and videos. See https://docs.ultralytics.com/modes/predict/ for help.\n",
      "\n",
      "Example:\n",
      "    results = model(source=..., stream=True)  # generator of Results objects\n",
      "    for r in results:\n",
      "        boxes = r.boxes  # Boxes object for bbox outputs\n",
      "        masks = r.masks  # Masks object for segment masks outputs\n",
      "        probs = r.probs  # Class probabilities for classification outputs\n",
      "\n",
      "video 1/1 (frame 1/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 65.5ms\n",
      "video 1/1 (frame 2/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 11.3ms\n",
      "video 1/1 (frame 3/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 10.4ms\n",
      "video 1/1 (frame 4/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 11.3ms\n",
      "video 1/1 (frame 5/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 10.2ms\n",
      "video 1/1 (frame 6/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 10.1ms\n",
      "video 1/1 (frame 7/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 8.7ms\n",
      "video 1/1 (frame 8/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 8.8ms\n",
      "video 1/1 (frame 9/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 9.8ms\n",
      "video 1/1 (frame 10/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 8.1ms\n",
      "video 1/1 (frame 11/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 8.3ms\n",
      "video 1/1 (frame 12/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 9.2ms\n",
      "video 1/1 (frame 13/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 8.5ms\n",
      "video 1/1 (frame 14/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 8.6ms\n",
      "video 1/1 (frame 15/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 8.8ms\n",
      "video 1/1 (frame 16/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 15.5ms\n",
      "video 1/1 (frame 17/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 7.9ms\n",
      "video 1/1 (frame 18/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 8.6ms\n",
      "video 1/1 (frame 19/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 14.0ms\n",
      "video 1/1 (frame 20/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 14.1ms\n",
      "video 1/1 (frame 21/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 13.2ms\n",
      "video 1/1 (frame 22/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 12.4ms\n",
      "video 1/1 (frame 23/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 7.7ms\n",
      "video 1/1 (frame 24/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 8.3ms\n",
      "video 1/1 (frame 25/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 9.1ms\n",
      "video 1/1 (frame 26/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 9.3ms\n",
      "video 1/1 (frame 27/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 9.1ms\n",
      "video 1/1 (frame 28/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 8.2ms\n",
      "video 1/1 (frame 29/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 8.2ms\n",
      "video 1/1 (frame 30/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 8.9ms\n",
      "video 1/1 (frame 31/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 8.2ms\n",
      "video 1/1 (frame 32/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 7.9ms\n",
      "video 1/1 (frame 33/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 7.3ms\n",
      "video 1/1 (frame 34/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 7.4ms\n",
      "video 1/1 (frame 35/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 7.6ms\n",
      "video 1/1 (frame 36/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 13.4ms\n",
      "video 1/1 (frame 37/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 7.3ms\n",
      "video 1/1 (frame 38/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 8.4ms\n",
      "video 1/1 (frame 39/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 7.6ms\n",
      "video 1/1 (frame 40/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 8.1ms\n",
      "video 1/1 (frame 41/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 8.1ms\n",
      "video 1/1 (frame 42/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 7.7ms\n",
      "video 1/1 (frame 43/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 8.0ms\n",
      "video 1/1 (frame 44/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 8.7ms\n",
      "video 1/1 (frame 45/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 10.2ms\n",
      "video 1/1 (frame 46/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 9.2ms\n",
      "video 1/1 (frame 47/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 16.0ms\n",
      "video 1/1 (frame 48/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 8.7ms\n",
      "video 1/1 (frame 49/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 11.6ms\n",
      "video 1/1 (frame 50/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 7.4ms\n",
      "video 1/1 (frame 51/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 7.5ms\n",
      "video 1/1 (frame 52/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 9.3ms\n",
      "video 1/1 (frame 53/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 7.9ms\n",
      "video 1/1 (frame 54/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 7.8ms\n",
      "video 1/1 (frame 55/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 7.6ms\n",
      "video 1/1 (frame 56/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 8.9ms\n",
      "video 1/1 (frame 57/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 9.6ms\n",
      "video 1/1 (frame 58/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 1 person, 8.9ms\n",
      "video 1/1 (frame 59/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 1 person, 9.8ms\n",
      "video 1/1 (frame 60/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 9.0ms\n",
      "video 1/1 (frame 61/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 8.9ms\n",
      "video 1/1 (frame 62/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 8.4ms\n",
      "video 1/1 (frame 63/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 1 car, 8.9ms\n",
      "video 1/1 (frame 64/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 7.1ms\n",
      "video 1/1 (frame 65/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 7.3ms\n",
      "video 1/1 (frame 66/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 10.0ms\n",
      "video 1/1 (frame 67/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 1 car, 10.9ms\n",
      "video 1/1 (frame 68/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 9.1ms\n",
      "video 1/1 (frame 69/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 8.5ms\n",
      "video 1/1 (frame 70/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 9.0ms\n",
      "video 1/1 (frame 71/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 1 cell phone, 9.9ms\n",
      "video 1/1 (frame 72/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 9.5ms\n",
      "video 1/1 (frame 73/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 1 cell phone, 10.4ms\n",
      "video 1/1 (frame 74/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 1 cell phone, 9.1ms\n",
      "video 1/1 (frame 75/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 1 cell phone, 9.6ms\n",
      "video 1/1 (frame 76/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 1 cell phone, 8.5ms\n",
      "video 1/1 (frame 77/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 1 cell phone, 8.1ms\n",
      "video 1/1 (frame 78/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 1 cell phone, 7.9ms\n",
      "video 1/1 (frame 79/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 1 cell phone, 7.1ms\n",
      "video 1/1 (frame 80/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 1 cell phone, 7.0ms\n",
      "video 1/1 (frame 81/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 1 cell phone, 7.9ms\n",
      "video 1/1 (frame 82/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 1 cell phone, 8.6ms\n",
      "video 1/1 (frame 83/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 1 cell phone, 7.2ms\n",
      "video 1/1 (frame 84/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 1 cell phone, 8.5ms\n",
      "video 1/1 (frame 85/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 1 cell phone, 10.6ms\n",
      "video 1/1 (frame 86/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 1 cell phone, 9.0ms\n",
      "video 1/1 (frame 87/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 1 cell phone, 9.1ms\n",
      "video 1/1 (frame 88/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 1 cell phone, 9.2ms\n",
      "video 1/1 (frame 89/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 1 cell phone, 8.1ms\n",
      "video 1/1 (frame 90/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 1 cell phone, 9.7ms\n",
      "video 1/1 (frame 91/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 1 cell phone, 8.2ms\n",
      "video 1/1 (frame 92/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 1 cell phone, 8.8ms\n",
      "video 1/1 (frame 93/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 1 cell phone, 9.1ms\n",
      "video 1/1 (frame 94/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 1 cell phone, 7.5ms\n",
      "video 1/1 (frame 95/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 1 cell phone, 8.1ms\n",
      "video 1/1 (frame 96/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 1 cell phone, 9.7ms\n",
      "video 1/1 (frame 97/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 1 cell phone, 9.1ms\n",
      "video 1/1 (frame 98/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 1 cell phone, 8.4ms\n",
      "video 1/1 (frame 99/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 1 cell phone, 9.3ms\n",
      "video 1/1 (frame 100/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 1 cell phone, 9.3ms\n",
      "video 1/1 (frame 101/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 1 cell phone, 7.9ms\n",
      "video 1/1 (frame 102/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 11.1ms\n",
      "video 1/1 (frame 103/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 1 cell phone, 8.5ms\n",
      "video 1/1 (frame 104/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 1 car, 8.2ms\n",
      "video 1/1 (frame 105/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 1 car, 15.2ms\n",
      "video 1/1 (frame 106/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 8.3ms\n",
      "video 1/1 (frame 107/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 7.6ms\n",
      "video 1/1 (frame 108/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 7.6ms\n",
      "video 1/1 (frame 109/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 7.6ms\n",
      "video 1/1 (frame 110/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 8.6ms\n",
      "video 1/1 (frame 111/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 7.5ms\n",
      "video 1/1 (frame 112/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 7.3ms\n",
      "video 1/1 (frame 113/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 7.4ms\n",
      "video 1/1 (frame 114/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 7.0ms\n",
      "video 1/1 (frame 115/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 8.9ms\n",
      "video 1/1 (frame 116/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 9.0ms\n",
      "video 1/1 (frame 117/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 8.2ms\n",
      "video 1/1 (frame 118/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 8.8ms\n",
      "video 1/1 (frame 119/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 9.3ms\n",
      "video 1/1 (frame 120/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 8.4ms\n",
      "video 1/1 (frame 121/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 8.4ms\n",
      "video 1/1 (frame 122/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 14.8ms\n",
      "video 1/1 (frame 123/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 10.8ms\n",
      "video 1/1 (frame 124/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 16.3ms\n",
      "video 1/1 (frame 125/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 9.1ms\n",
      "video 1/1 (frame 126/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 7.6ms\n",
      "video 1/1 (frame 127/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 7.5ms\n",
      "video 1/1 (frame 128/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 6.8ms\n",
      "video 1/1 (frame 129/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 7.3ms\n",
      "video 1/1 (frame 130/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 10.5ms\n",
      "video 1/1 (frame 131/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 7.9ms\n",
      "video 1/1 (frame 132/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 7.4ms\n",
      "video 1/1 (frame 133/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 7.8ms\n",
      "video 1/1 (frame 134/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 7.4ms\n",
      "video 1/1 (frame 135/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 8.4ms\n",
      "video 1/1 (frame 136/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 7.2ms\n",
      "video 1/1 (frame 137/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 7.7ms\n",
      "video 1/1 (frame 138/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 18.2ms\n",
      "video 1/1 (frame 139/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 8.4ms\n",
      "video 1/1 (frame 140/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 9.9ms\n",
      "video 1/1 (frame 141/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 9.8ms\n",
      "video 1/1 (frame 142/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 8.9ms\n",
      "video 1/1 (frame 143/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 8.5ms\n",
      "video 1/1 (frame 144/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 8.7ms\n",
      "video 1/1 (frame 145/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 8.0ms\n",
      "video 1/1 (frame 146/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 17.4ms\n",
      "video 1/1 (frame 147/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 7.4ms\n",
      "video 1/1 (frame 148/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 8.6ms\n",
      "video 1/1 (frame 149/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 9.2ms\n",
      "video 1/1 (frame 150/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 13.4ms\n",
      "video 1/1 (frame 151/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 8.4ms\n",
      "video 1/1 (frame 152/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 7.6ms\n",
      "video 1/1 (frame 153/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 8.6ms\n",
      "video 1/1 (frame 154/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 9.0ms\n",
      "video 1/1 (frame 155/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 8.8ms\n",
      "video 1/1 (frame 156/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 8.6ms\n",
      "video 1/1 (frame 157/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 8.9ms\n",
      "video 1/1 (frame 158/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 10.3ms\n",
      "video 1/1 (frame 159/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 7.1ms\n",
      "video 1/1 (frame 160/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 7.3ms\n",
      "video 1/1 (frame 161/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 7.0ms\n",
      "video 1/1 (frame 162/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 8.0ms\n",
      "video 1/1 (frame 163/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 8.9ms\n",
      "video 1/1 (frame 164/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 9.1ms\n",
      "video 1/1 (frame 165/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 9.5ms\n",
      "video 1/1 (frame 166/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 8.0ms\n",
      "video 1/1 (frame 167/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 7.5ms\n",
      "video 1/1 (frame 168/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 15.3ms\n",
      "video 1/1 (frame 169/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 7.8ms\n",
      "video 1/1 (frame 170/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 13.9ms\n",
      "video 1/1 (frame 171/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 12.1ms\n",
      "video 1/1 (frame 172/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 7.1ms\n",
      "video 1/1 (frame 173/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 7.5ms\n",
      "video 1/1 (frame 174/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 7.5ms\n",
      "video 1/1 (frame 175/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 13.1ms\n",
      "video 1/1 (frame 176/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 6.9ms\n",
      "video 1/1 (frame 177/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 7.8ms\n",
      "video 1/1 (frame 178/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 8.9ms\n",
      "video 1/1 (frame 179/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 9.2ms\n",
      "video 1/1 (frame 180/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 7.9ms\n",
      "video 1/1 (frame 181/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 7.9ms\n",
      "video 1/1 (frame 182/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 7.9ms\n",
      "video 1/1 (frame 183/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 8.4ms\n",
      "video 1/1 (frame 184/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 12.3ms\n",
      "video 1/1 (frame 185/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 1 car, 20.1ms\n",
      "video 1/1 (frame 186/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 1 cell phone, 21.3ms\n",
      "video 1/1 (frame 187/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 1 cell phone, 11.0ms\n",
      "video 1/1 (frame 188/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 1 cell phone, 10.1ms\n",
      "video 1/1 (frame 189/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 1 cup, 9.1ms\n",
      "video 1/1 (frame 190/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 1 cup, 9.9ms\n",
      "video 1/1 (frame 191/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 16.9ms\n",
      "video 1/1 (frame 192/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 1 sports ball, 15.9ms\n",
      "video 1/1 (frame 193/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 1 person, 1 cell phone, 11.9ms\n",
      "video 1/1 (frame 194/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 1 cell phone, 11.4ms\n",
      "video 1/1 (frame 195/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 1 cell phone, 10.6ms\n",
      "video 1/1 (frame 196/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 1 cell phone, 10.4ms\n",
      "video 1/1 (frame 197/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 1 cell phone, 11.3ms\n",
      "video 1/1 (frame 198/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 1 suitcase, 11.4ms\n",
      "video 1/1 (frame 199/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 1 suitcase, 9.2ms\n",
      "video 1/1 (frame 200/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 1 suitcase, 8.2ms\n",
      "video 1/1 (frame 201/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 1 suitcase, 1 cell phone, 13.3ms\n",
      "video 1/1 (frame 202/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 1 suitcase, 1 cell phone, 10.9ms\n",
      "video 1/1 (frame 203/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 2 cell phones, 10.3ms\n",
      "video 1/1 (frame 204/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 2 cell phones, 7.8ms\n",
      "video 1/1 (frame 205/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 2 cell phones, 8.3ms\n",
      "video 1/1 (frame 206/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 2 cell phones, 9.5ms\n",
      "video 1/1 (frame 207/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 2 cell phones, 11.6ms\n",
      "video 1/1 (frame 208/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 2 cell phones, 11.1ms\n",
      "video 1/1 (frame 209/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 2 cell phones, 8.0ms\n",
      "video 1/1 (frame 210/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 2 cell phones, 9.9ms\n",
      "video 1/1 (frame 211/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 2 cell phones, 9.0ms\n",
      "video 1/1 (frame 212/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 2 cell phones, 8.8ms\n",
      "video 1/1 (frame 213/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 2 cell phones, 10.3ms\n",
      "video 1/1 (frame 214/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 2 cell phones, 8.4ms\n",
      "video 1/1 (frame 215/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 2 cell phones, 10.0ms\n",
      "video 1/1 (frame 216/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 2 cell phones, 9.8ms\n",
      "video 1/1 (frame 217/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 2 cell phones, 8.2ms\n",
      "video 1/1 (frame 218/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 2 cell phones, 8.0ms\n",
      "video 1/1 (frame 219/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 2 cell phones, 10.6ms\n",
      "video 1/1 (frame 220/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 2 cell phones, 6.8ms\n",
      "video 1/1 (frame 221/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 1 car, 2 cell phones, 12.8ms\n",
      "video 1/1 (frame 222/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 1 car, 1 bus, 6.9ms\n",
      "video 1/1 (frame 223/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 1 car, 1 bus, 9.2ms\n",
      "video 1/1 (frame 224/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 1 car, 1 cell phone, 8.2ms\n",
      "video 1/1 (frame 225/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 1 car, 1 cell phone, 15.2ms\n",
      "video 1/1 (frame 226/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 1 car, 1 cell phone, 7.7ms\n",
      "video 1/1 (frame 227/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 1 cell phone, 9.0ms\n",
      "video 1/1 (frame 228/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 1 cell phone, 8.2ms\n",
      "video 1/1 (frame 229/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 1 cell phone, 7.9ms\n",
      "video 1/1 (frame 230/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 1 cell phone, 9.0ms\n",
      "video 1/1 (frame 231/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 1 cell phone, 8.3ms\n",
      "video 1/1 (frame 232/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 1 car, 10.7ms\n",
      "video 1/1 (frame 233/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 1 car, 6.8ms\n",
      "video 1/1 (frame 234/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 1 car, 1 cell phone, 15.3ms\n",
      "video 1/1 (frame 235/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 1 cell phone, 16.3ms\n",
      "video 1/1 (frame 236/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 7.5ms\n",
      "video 1/1 (frame 237/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 1 car, 7.8ms\n",
      "video 1/1 (frame 238/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 8.3ms\n",
      "video 1/1 (frame 239/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 8.8ms\n",
      "video 1/1 (frame 240/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 9.1ms\n",
      "video 1/1 (frame 241/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 8.9ms\n",
      "video 1/1 (frame 242/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 9.0ms\n",
      "video 1/1 (frame 243/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 8.3ms\n",
      "video 1/1 (frame 244/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 8.5ms\n",
      "video 1/1 (frame 245/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 8.0ms\n",
      "video 1/1 (frame 246/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 7.9ms\n",
      "video 1/1 (frame 247/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 8.6ms\n",
      "video 1/1 (frame 248/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 19.7ms\n",
      "video 1/1 (frame 249/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 12.0ms\n",
      "video 1/1 (frame 250/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 9.2ms\n",
      "video 1/1 (frame 251/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 8.9ms\n",
      "video 1/1 (frame 252/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 7.6ms\n",
      "video 1/1 (frame 253/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 8.0ms\n",
      "video 1/1 (frame 254/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 8.9ms\n",
      "video 1/1 (frame 255/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 9.6ms\n",
      "video 1/1 (frame 256/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 7.1ms\n",
      "video 1/1 (frame 257/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 9.2ms\n",
      "video 1/1 (frame 258/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 9.6ms\n",
      "video 1/1 (frame 259/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 8.7ms\n",
      "video 1/1 (frame 260/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 10.1ms\n",
      "video 1/1 (frame 261/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 7.4ms\n",
      "video 1/1 (frame 262/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 8.4ms\n",
      "video 1/1 (frame 263/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 8.5ms\n",
      "video 1/1 (frame 264/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 8.3ms\n",
      "video 1/1 (frame 265/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 8.5ms\n",
      "video 1/1 (frame 266/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 15.3ms\n",
      "video 1/1 (frame 267/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 7.9ms\n",
      "video 1/1 (frame 268/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 7.6ms\n",
      "video 1/1 (frame 269/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 7.6ms\n",
      "video 1/1 (frame 270/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 8.1ms\n",
      "video 1/1 (frame 271/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 10.9ms\n",
      "video 1/1 (frame 272/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 10.1ms\n",
      "video 1/1 (frame 273/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 6.7ms\n",
      "video 1/1 (frame 274/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 7.3ms\n",
      "video 1/1 (frame 275/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 8.8ms\n",
      "video 1/1 (frame 276/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 7.3ms\n",
      "video 1/1 (frame 277/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 7.2ms\n",
      "video 1/1 (frame 278/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 9.7ms\n",
      "video 1/1 (frame 279/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 16.0ms\n",
      "video 1/1 (frame 280/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 7.3ms\n",
      "video 1/1 (frame 281/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 1 airplane, 15.3ms\n",
      "video 1/1 (frame 282/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 1 airplane, 7.1ms\n",
      "video 1/1 (frame 283/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 7.9ms\n",
      "video 1/1 (frame 284/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 8.9ms\n",
      "video 1/1 (frame 285/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 7.3ms\n",
      "video 1/1 (frame 286/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 1 airplane, 8.6ms\n",
      "video 1/1 (frame 287/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 1 airplane, 7.0ms\n",
      "video 1/1 (frame 288/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 7.2ms\n",
      "video 1/1 (frame 289/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 7.0ms\n",
      "video 1/1 (frame 290/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 1 airplane, 7.2ms\n",
      "video 1/1 (frame 291/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 1 airplane, 6.9ms\n",
      "video 1/1 (frame 292/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 1 airplane, 7.6ms\n",
      "video 1/1 (frame 293/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 7.2ms\n",
      "video 1/1 (frame 294/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 10.3ms\n",
      "video 1/1 (frame 295/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 7.4ms\n",
      "video 1/1 (frame 296/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 8.1ms\n",
      "video 1/1 (frame 297/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 8.9ms\n",
      "video 1/1 (frame 298/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 8.2ms\n",
      "video 1/1 (frame 299/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 8.1ms\n",
      "video 1/1 (frame 300/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 7.9ms\n",
      "video 1/1 (frame 301/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 8.0ms\n",
      "video 1/1 (frame 302/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 16.3ms\n",
      "video 1/1 (frame 303/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 7.9ms\n",
      "video 1/1 (frame 304/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 7.4ms\n",
      "video 1/1 (frame 305/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 10.2ms\n",
      "video 1/1 (frame 306/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 1 airplane, 16.0ms\n",
      "video 1/1 (frame 307/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 19.3ms\n",
      "video 1/1 (frame 308/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 7.7ms\n",
      "video 1/1 (frame 309/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 8.1ms\n",
      "video 1/1 (frame 310/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 18.5ms\n",
      "video 1/1 (frame 311/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 9.2ms\n",
      "video 1/1 (frame 312/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 8.3ms\n",
      "video 1/1 (frame 313/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 8.6ms\n",
      "video 1/1 (frame 314/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 12.4ms\n",
      "video 1/1 (frame 315/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 7.1ms\n",
      "video 1/1 (frame 316/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 8.6ms\n",
      "video 1/1 (frame 317/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 11.8ms\n",
      "video 1/1 (frame 318/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 8.1ms\n",
      "video 1/1 (frame 319/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 1 cell phone, 8.3ms\n",
      "video 1/1 (frame 320/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 1 cell phone, 7.8ms\n",
      "video 1/1 (frame 321/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 7.3ms\n",
      "video 1/1 (frame 322/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 1 cup, 1 spoon, 10.1ms\n",
      "video 1/1 (frame 323/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 1 bottle, 7.8ms\n",
      "video 1/1 (frame 324/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 1 cell phone, 15.3ms\n",
      "video 1/1 (frame 325/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 1 cell phone, 7.1ms\n",
      "video 1/1 (frame 326/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 1 cell phone, 7.0ms\n",
      "video 1/1 (frame 327/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 1 cell phone, 7.6ms\n",
      "video 1/1 (frame 328/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 1 cell phone, 7.5ms\n",
      "video 1/1 (frame 329/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 1 cell phone, 9.9ms\n",
      "video 1/1 (frame 330/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 1 cell phone, 8.7ms\n",
      "video 1/1 (frame 331/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 1 cell phone, 7.1ms\n",
      "video 1/1 (frame 332/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 1 cell phone, 7.4ms\n",
      "video 1/1 (frame 333/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 1 cell phone, 7.7ms\n",
      "video 1/1 (frame 334/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 1 cell phone, 9.0ms\n",
      "video 1/1 (frame 335/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 1 cell phone, 7.8ms\n",
      "video 1/1 (frame 336/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 1 cell phone, 9.0ms\n",
      "video 1/1 (frame 337/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 1 cell phone, 8.0ms\n",
      "video 1/1 (frame 338/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 1 cell phone, 8.5ms\n",
      "video 1/1 (frame 339/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 1 cell phone, 7.4ms\n",
      "video 1/1 (frame 340/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 1 cell phone, 8.1ms\n",
      "video 1/1 (frame 341/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 1 cell phone, 11.1ms\n",
      "video 1/1 (frame 342/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 1 cell phone, 16.0ms\n",
      "video 1/1 (frame 343/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 7.5ms\n",
      "video 1/1 (frame 344/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 1 car, 7.9ms\n",
      "video 1/1 (frame 345/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 1 car, 7.8ms\n",
      "video 1/1 (frame 346/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 1 car, 9.6ms\n",
      "video 1/1 (frame 347/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 1 car, 8.6ms\n",
      "video 1/1 (frame 348/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 9.6ms\n",
      "video 1/1 (frame 349/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 9.1ms\n",
      "video 1/1 (frame 350/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 9.2ms\n",
      "video 1/1 (frame 351/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 8.5ms\n",
      "video 1/1 (frame 352/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 9.2ms\n",
      "video 1/1 (frame 353/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 10.2ms\n",
      "video 1/1 (frame 354/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 8.1ms\n",
      "video 1/1 (frame 355/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 9.0ms\n",
      "video 1/1 (frame 356/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 7.7ms\n",
      "video 1/1 (frame 357/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 15.0ms\n",
      "video 1/1 (frame 358/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 21.9ms\n",
      "video 1/1 (frame 359/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 12.9ms\n",
      "video 1/1 (frame 360/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 9.2ms\n",
      "video 1/1 (frame 361/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 8.3ms\n",
      "video 1/1 (frame 362/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 7.6ms\n",
      "video 1/1 (frame 363/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 7.6ms\n",
      "video 1/1 (frame 364/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 7.7ms\n",
      "video 1/1 (frame 365/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 8.1ms\n",
      "video 1/1 (frame 366/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 7.9ms\n",
      "video 1/1 (frame 367/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 6.9ms\n",
      "video 1/1 (frame 368/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 7.9ms\n",
      "video 1/1 (frame 369/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 8.3ms\n",
      "video 1/1 (frame 370/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 7.5ms\n",
      "video 1/1 (frame 371/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 8.0ms\n",
      "video 1/1 (frame 372/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 9.4ms\n",
      "video 1/1 (frame 373/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 8.9ms\n",
      "video 1/1 (frame 374/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 7.3ms\n",
      "video 1/1 (frame 375/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 14.5ms\n",
      "video 1/1 (frame 376/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 9.0ms\n",
      "video 1/1 (frame 377/377) c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\car-detection.mp4: 384x640 (no detections), 15.9ms\n",
      "Speed: 1.8ms preprocess, 9.5ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2  # OpenCV để giải phóng tài nguyên\n",
    "\n",
    "# Dự đoán trên video    \n",
    "model2 = YOLO(\"trained_model.pt\")\n",
    "results = model2.predict('car-detection.mp4',show=True)  # predict on a video\n",
    "# results = model2('car-detection.mp4',save=True,show=True)  # predict on a video\n",
    "# results = model2.track('car-detection.mp4',save=True,show=True)  # predict on a video\n",
    "\n",
    "# results=model.predict(\"download.jpg\",show=True)  # predict on an image\n",
    "# Đảm bảo giải phóng tài nguyên khi tắt cửa sổ ảnh\n",
    "# Giữ cửa sổ ảnh mở cho đến khi nhấn phím bất kỳ\n",
    "cv2.waitKey(0)  # Chờ cho đến khi bạn nhấn một phím\n",
    "cv2.destroyAllWindows()  # Đóng tất cả cửa sổ OpenCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "55067530",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n-cls.pt to 'yolo11n-cls.pt'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5.52M/5.52M [00:00<00:00, 7.36MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\download.jpg: 224x224 trolleybus 0.95, minibus 0.03, passenger_car 0.01, streetcar 0.01, garbage_truck 0.00, 4.4ms\n",
      "Speed: 17.4ms preprocess, 4.4ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n"
     ]
    }
   ],
   "source": [
    "model3=YOLO(\"yolo11n-cls.pt\")\n",
    "results = model3.predict('download.jpg',show=True)  # predict on an image\n",
    "cv2.waitKey(0)  # Chờ cho đến khi bạn nhấn một phím\n",
    "cv2.destroyAllWindows()  # Đóng tất cả cửa sổ OpenCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5d9a0fca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 c:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\download.jpg: 480x640 2 buss, 29.5ms\n",
      "Speed: 2.7ms preprocess, 29.5ms inference, 3.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001b[1mruns\\segment\\predict\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "model3=YOLO(\"yolo11n-seg.pt\")\n",
    "results = model3.predict('download.jpg',show=True,save=True)  # predict on an image\n",
    "cv2.waitKey(0)  # Chờ cho đến khi bạn nhấn một phím\n",
    "cv2.destroyAllWindows()  # Đóng tất cả cửa sổ OpenCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3561c12e",
   "metadata": {},
   "source": [
    "# Tập train model trên yolov8\n",
    "mkdir train\\images\n",
    "\n",
    "mkdir train\\labels\n",
    "\n",
    "mkdir train\n",
    "\n",
    "move *.jpg train\\images\n",
    "\n",
    "move *.txt train\\labels\n",
    "\n",
    "echo train: dataset/images/train > data.yaml\n",
    "\n",
    "echo val: dataset/images/val >> data.yaml\n",
    "\n",
    "echo nc: 1 >> data.yaml \n",
    "\n",
    "echo names: ['fire'] >> data.yaml "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "13bc292f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.3.111 available  Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.89  Python-3.11.5 torch-2.6.0+cu126 CUDA:0 (NVIDIA GeForce RTX 3050 Laptop GPU, 4096MiB)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=detect, mode=train, model=yolo11n.pt, data=data.yaml, epochs=100, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train7, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs\\detect\\train7\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n",
      "  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      "  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
      "  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      "  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    111296  ultralytics.nn.modules.block.C3k2            [384, 128, 1, False]          \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  1     32096  ultralytics.nn.modules.block.C3k2            [256, 64, 1, False]           \n",
      " 17                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  1     86720  ultralytics.nn.modules.block.C3k2            [192, 128, 1, False]          \n",
      " 20                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  1    378880  ultralytics.nn.modules.block.C3k2            [384, 256, 1, True]           \n",
      " 23        [16, 19, 22]  1    430867  ultralytics.nn.modules.head.Detect           [1, [64, 128, 256]]           \n",
      "YOLO11n summary: 181 layers, 2,590,035 parameters, 2,590,019 gradients, 6.4 GFLOPs\n",
      "\n",
      "Transferred 448/499 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs\\detect\\train7', view at http://localhost:6006/\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\train\\labels.cache... 253 images, 212 backgrounds, 0 corrupt: 100%|██████████| 460/460 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  C:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\train\\images\\000123.jpg: corrupt JPEG restored and saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\train\\labels.cache... 253 images, 212 backgrounds, 0 corrupt: 100%|██████████| 460/460 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  C:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\train\\images\\000123.jpg: corrupt JPEG restored and saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs\\detect\\train7\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 81 weight(decay=0.0), 88 weight(decay=0.0005), 87 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added \n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mruns\\detect\\train7\u001b[0m\n",
      "Starting training for 100 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      1/100      2.78G      1.718      3.311      1.787         19        640: 100%|██████████| 29/29 [00:10<00:00,  2.86it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:04<00:00,  3.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        460        410    0.00278      0.937      0.153     0.0616\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      2/100      2.78G      1.829      3.134      1.905         13        640: 100%|██████████| 29/29 [00:09<00:00,  3.02it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:06<00:00,  2.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        460        410      0.336     0.0561      0.146     0.0472\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      3/100      2.78G      1.888      2.943      1.937         17        640: 100%|██████████| 29/29 [00:10<00:00,  2.86it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:06<00:00,  2.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        460        410      0.215      0.237      0.126     0.0376\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      4/100      2.78G      1.893       2.78      1.968         20        640: 100%|██████████| 29/29 [00:11<00:00,  2.48it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:06<00:00,  2.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        460        410      0.163      0.178     0.0717     0.0227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      5/100      2.78G      1.931      2.717      1.942         24        640: 100%|██████████| 29/29 [00:09<00:00,  3.03it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:04<00:00,  3.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        460        410     0.0455      0.249      0.031     0.0103\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      6/100      2.78G      1.925      2.632      1.909         22        640: 100%|██████████| 29/29 [00:08<00:00,  3.49it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:04<00:00,  3.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        460        410      0.209       0.18      0.111     0.0405\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      7/100      2.78G      1.932       2.54      1.947         18        640: 100%|██████████| 29/29 [00:08<00:00,  3.31it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:04<00:00,  3.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        460        410      0.164      0.229      0.111     0.0347\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      8/100      2.78G      1.885      2.493      1.871         28        640: 100%|██████████| 29/29 [00:09<00:00,  3.06it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:05<00:00,  2.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        460        410      0.358      0.317      0.257     0.0947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      9/100      2.78G      1.916      2.465      1.943         14        640: 100%|██████████| 29/29 [00:11<00:00,  2.56it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:05<00:00,  2.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        460        410      0.276      0.388      0.213     0.0824\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     10/100      2.78G      1.856       2.36      1.863         22        640: 100%|██████████| 29/29 [00:10<00:00,  2.67it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:04<00:00,  3.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        460        410      0.363      0.371      0.305      0.115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     11/100      2.78G      1.834      2.278      1.847         21        640: 100%|██████████| 29/29 [00:10<00:00,  2.74it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:04<00:00,  3.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        460        410      0.302      0.383      0.255      0.103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     12/100      2.78G      1.804      2.211        1.8         10        640: 100%|██████████| 29/29 [00:12<00:00,  2.23it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:04<00:00,  3.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        460        410      0.367      0.456      0.327       0.14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     13/100      2.78G      1.839      2.263      1.888         19        640: 100%|██████████| 29/29 [00:12<00:00,  2.24it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:05<00:00,  2.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        460        410      0.331      0.429      0.318      0.129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     14/100      2.78G       1.77      2.243       1.82         16        640: 100%|██████████| 29/29 [00:14<00:00,  2.05it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:07<00:00,  2.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        460        410      0.445      0.389      0.375      0.166\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     15/100      2.78G       1.81      2.135      1.843         33        640: 100%|██████████| 29/29 [00:12<00:00,  2.32it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:06<00:00,  2.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        460        410      0.443      0.446      0.401       0.17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     16/100      2.78G      1.792      2.127      1.825         37        640: 100%|██████████| 29/29 [00:13<00:00,  2.10it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:06<00:00,  2.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        460        410      0.462      0.446      0.397      0.174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     17/100      2.79G      1.717      2.098      1.786         27        640: 100%|██████████| 29/29 [00:13<00:00,  2.16it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:07<00:00,  2.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        460        410      0.437      0.459      0.409       0.18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     18/100      2.81G      1.691      1.987      1.738         22        640: 100%|██████████| 29/29 [00:13<00:00,  2.09it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:07<00:00,  1.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        460        410      0.498      0.466      0.464      0.238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     19/100      2.82G       1.74       2.12      1.746         16        640: 100%|██████████| 29/29 [00:15<00:00,  1.83it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:07<00:00,  2.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        460        410      0.423      0.423      0.373       0.16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     20/100      2.84G      1.699      2.031      1.742         30        640: 100%|██████████| 29/29 [00:16<00:00,  1.78it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:06<00:00,  2.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        460        410      0.516       0.45      0.465      0.217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     21/100      2.84G      1.735      1.956      1.767         34        640: 100%|██████████| 29/29 [00:13<00:00,  2.20it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:06<00:00,  2.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        460        410      0.527      0.488      0.484      0.227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     22/100      2.84G      1.666      1.954      1.735         17        640: 100%|██████████| 29/29 [00:16<00:00,  1.74it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:05<00:00,  2.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        460        410      0.536      0.488      0.488      0.239\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     23/100      2.84G      1.698      1.943      1.756         20        640: 100%|██████████| 29/29 [00:16<00:00,  1.79it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:06<00:00,  2.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        460        410       0.51      0.506      0.481      0.236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     24/100      2.84G      1.651      1.942       1.72         19        640: 100%|██████████| 29/29 [00:17<00:00,  1.63it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:06<00:00,  2.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        460        410      0.511      0.488      0.495      0.247\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     25/100      2.84G      1.608       1.87      1.691         28        640: 100%|██████████| 29/29 [00:15<00:00,  1.83it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:06<00:00,  2.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        460        410      0.488      0.413      0.405      0.195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     26/100      2.84G      1.647      1.838      1.696         33        640: 100%|██████████| 29/29 [00:16<00:00,  1.74it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:07<00:00,  2.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        460        410      0.519      0.495      0.506      0.248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     27/100      2.84G      1.607      1.829      1.644         29        640: 100%|██████████| 29/29 [00:17<00:00,  1.66it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:06<00:00,  2.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        460        410      0.565      0.478      0.526      0.277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     28/100      2.84G      1.603      1.871      1.686         16        640: 100%|██████████| 29/29 [00:17<00:00,  1.70it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:04<00:00,  3.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        460        410      0.557       0.49      0.509      0.256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     29/100      2.84G       1.65      1.872      1.711         23        640: 100%|██████████| 29/29 [00:17<00:00,  1.69it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:05<00:00,  2.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        460        410      0.517      0.456      0.482      0.235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     30/100      2.84G      1.553      1.779      1.667         24        640: 100%|██████████| 29/29 [00:15<00:00,  1.84it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:06<00:00,  2.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        460        410      0.576      0.517       0.56       0.29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     31/100      2.84G      1.642      1.904      1.715         28        640: 100%|██████████| 29/29 [00:18<00:00,  1.57it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:06<00:00,  2.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        460        410      0.585      0.512      0.521      0.276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     32/100      2.84G      1.608      1.827      1.699         28        640: 100%|██████████| 29/29 [00:18<00:00,  1.61it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:06<00:00,  2.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        460        410      0.587      0.512      0.563      0.301\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     33/100      2.84G      1.589      1.828       1.65         11        640: 100%|██████████| 29/29 [00:19<00:00,  1.51it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:06<00:00,  2.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        460        410       0.61      0.573      0.603      0.334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     34/100      2.84G      1.603      1.764      1.657         19        640: 100%|██████████| 29/29 [00:16<00:00,  1.77it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        460        410      0.575      0.612      0.618      0.329\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     35/100      2.84G      1.611      1.701      1.655         24        640: 100%|██████████| 29/29 [00:18<00:00,  1.53it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:05<00:00,  2.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        460        410      0.637      0.529      0.595      0.323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     36/100      2.84G      1.556      1.703      1.646         34        640: 100%|██████████| 29/29 [00:20<00:00,  1.39it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        460        410      0.613      0.588      0.604      0.329\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     37/100      2.84G      1.561      1.732       1.66         22        640: 100%|██████████| 29/29 [00:18<00:00,  1.58it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:06<00:00,  2.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        460        410      0.601      0.568       0.55      0.302\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     38/100      2.84G      1.522      1.721      1.591         41        640: 100%|██████████| 29/29 [00:23<00:00,  1.26it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        460        410        0.5      0.512      0.494      0.265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     39/100      2.84G      1.531      1.699      1.605         21        640: 100%|██████████| 29/29 [00:21<00:00,  1.33it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        460        410      0.579      0.598      0.607      0.323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     40/100      2.84G      1.536      1.658      1.614         22        640: 100%|██████████| 29/29 [00:19<00:00,  1.48it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        460        410      0.644      0.576      0.643      0.364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     41/100      2.84G      1.542      1.633      1.617         20        640: 100%|██████████| 29/29 [00:18<00:00,  1.54it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        460        410      0.635      0.622      0.643      0.356\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     42/100      2.84G      1.542      1.635      1.611         23        640: 100%|██████████| 29/29 [00:17<00:00,  1.66it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:06<00:00,  2.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        460        410      0.622      0.601      0.655      0.367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     43/100      2.84G      1.465      1.631      1.579         17        640: 100%|██████████| 29/29 [00:17<00:00,  1.69it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:06<00:00,  2.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        460        410      0.602      0.607      0.635      0.362\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     44/100      2.84G      1.515      1.623        1.6         14        640: 100%|██████████| 29/29 [00:25<00:00,  1.15it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:06<00:00,  2.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        460        410      0.639      0.573      0.645      0.373\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     45/100      2.84G      1.476      1.572      1.598         26        640: 100%|██████████| 29/29 [00:20<00:00,  1.42it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:05<00:00,  2.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        460        410      0.703      0.556      0.663      0.385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     46/100      2.84G      1.471      1.612      1.553         21        640: 100%|██████████| 29/29 [00:23<00:00,  1.26it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:05<00:00,  2.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        460        410      0.603      0.554      0.605      0.348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     47/100      2.84G      1.489      1.564      1.557         10        640: 100%|██████████| 29/29 [00:22<00:00,  1.26it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:06<00:00,  2.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        460        410      0.649      0.624      0.653      0.389\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     48/100      2.84G      1.466      1.618      1.574         15        640: 100%|██████████| 29/29 [00:24<00:00,  1.19it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:07<00:00,  1.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        460        410      0.669      0.661      0.699      0.415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     49/100      2.84G      1.416      1.555      1.539         20        640: 100%|██████████| 29/29 [00:20<00:00,  1.40it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:06<00:00,  2.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        460        410      0.704      0.617      0.701      0.426\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     50/100      2.84G      1.415      1.503      1.523         16        640: 100%|██████████| 29/29 [00:29<00:00,  1.00s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:06<00:00,  2.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        460        410      0.661      0.644      0.698      0.405\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     51/100      2.84G      1.418      1.513      1.553         15        640: 100%|██████████| 29/29 [00:18<00:00,  1.53it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:07<00:00,  2.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        460        410       0.67      0.673      0.725      0.425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     52/100      2.84G      1.468      1.485      1.541         35        640: 100%|██████████| 29/29 [00:23<00:00,  1.26it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        460        410      0.689       0.67      0.726      0.439\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     53/100      2.84G      1.399      1.477      1.526         27        640: 100%|██████████| 29/29 [00:20<00:00,  1.41it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        460        410      0.668      0.643      0.711      0.432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     54/100      2.84G      1.424      1.532       1.54         23        640: 100%|██████████| 29/29 [00:20<00:00,  1.39it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:08<00:00,  1.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        460        410      0.726       0.71      0.775      0.473\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     55/100      2.84G      1.369      1.556      1.512         21        640: 100%|██████████| 29/29 [00:27<00:00,  1.04it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:06<00:00,  2.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        460        410      0.689      0.678      0.748      0.442\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     56/100      2.84G       1.37      1.492      1.503         15        640: 100%|██████████| 29/29 [00:27<00:00,  1.05it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:07<00:00,  1.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        460        410      0.715      0.662      0.756      0.458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     57/100      2.84G      1.369      1.403      1.488         23        640: 100%|██████████| 29/29 [00:27<00:00,  1.07it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        460        410      0.747      0.698      0.775      0.482\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     58/100      2.84G      1.381      1.418      1.501         23        640: 100%|██████████| 29/29 [00:27<00:00,  1.07it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:07<00:00,  1.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        460        410      0.711      0.696      0.756      0.465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     59/100      2.84G      1.286       1.34      1.423         22        640: 100%|██████████| 29/29 [00:18<00:00,  1.57it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:07<00:00,  2.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        460        410      0.744      0.732      0.808      0.515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     60/100      2.84G      1.364      1.445      1.487         22        640: 100%|██████████| 29/29 [00:28<00:00,  1.02it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:07<00:00,  1.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        460        410      0.781      0.702      0.792      0.502\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     61/100      2.84G       1.35      1.419      1.475         23        640: 100%|██████████| 29/29 [00:25<00:00,  1.14it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:08<00:00,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        460        410      0.736      0.721        0.8       0.51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     62/100      2.84G      1.364      1.367      1.501         20        640: 100%|██████████| 29/29 [00:20<00:00,  1.39it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:08<00:00,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        460        410      0.783      0.707      0.801      0.513\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     63/100      2.84G       1.32      1.335      1.456         23        640: 100%|██████████| 29/29 [00:23<00:00,  1.24it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:07<00:00,  2.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        460        410      0.743      0.727       0.79      0.513\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     64/100      2.84G      1.309      1.364      1.456         26        640: 100%|██████████| 29/29 [00:24<00:00,  1.17it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:07<00:00,  1.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        460        410      0.787      0.758      0.836      0.552\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     65/100      2.84G      1.334      1.403      1.457         23        640: 100%|██████████| 29/29 [00:26<00:00,  1.09it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:08<00:00,  1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        460        410      0.745      0.691      0.772       0.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     66/100      2.84G      1.322      1.352      1.452         17        640: 100%|██████████| 29/29 [00:27<00:00,  1.06it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:08<00:00,  1.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        460        410      0.753      0.788      0.837      0.546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     67/100      2.84G      1.301      1.335      1.444         30        640: 100%|██████████| 29/29 [00:24<00:00,  1.20it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        460        410      0.761      0.692      0.766      0.465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     68/100      2.84G      1.325      1.295      1.449         20        640: 100%|██████████| 29/29 [00:22<00:00,  1.32it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:09<00:00,  1.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        460        410      0.824       0.74      0.839      0.545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     69/100      2.84G      1.286      1.297      1.426         17        640: 100%|██████████| 29/29 [00:22<00:00,  1.30it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:11<00:00,  1.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        460        410        0.8       0.77      0.839      0.553\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     70/100      2.84G      1.277      1.291      1.424         22        640: 100%|██████████| 29/29 [00:27<00:00,  1.05it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:12<00:00,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        460        410      0.785      0.747      0.827      0.549\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     71/100      2.84G      1.274      1.281      1.415         23        640: 100%|██████████| 29/29 [00:21<00:00,  1.32it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:11<00:00,  1.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        460        410       0.82      0.737      0.846      0.573\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     72/100      2.84G      1.225      1.283      1.378         30        640: 100%|██████████| 29/29 [00:22<00:00,  1.29it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:11<00:00,  1.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        460        410      0.819      0.749      0.847      0.557\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     73/100      2.84G      1.246      1.273      1.394         23        640: 100%|██████████| 29/29 [00:21<00:00,  1.33it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:10<00:00,  1.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        460        410      0.817      0.749      0.847      0.572\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     74/100      2.84G      1.238       1.25      1.408         24        640: 100%|██████████| 29/29 [00:26<00:00,  1.08it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:22<00:00,  1.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        460        410        0.8      0.793      0.869      0.578\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     75/100      2.84G      1.258      1.327      1.404         24        640: 100%|██████████| 29/29 [00:50<00:00,  1.74s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:28<00:00,  1.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        460        410      0.803      0.776      0.858      0.561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     76/100      2.84G      1.243      1.268      1.422         23        640: 100%|██████████| 29/29 [00:44<00:00,  1.52s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:20<00:00,  1.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        460        410      0.785      0.829      0.871      0.594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     77/100      2.84G      1.204      1.208      1.382         21        640: 100%|██████████| 29/29 [00:45<00:00,  1.58s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:28<00:00,  1.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        460        410      0.801      0.812      0.882      0.602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     78/100      2.84G      1.235      1.214        1.4         29        640: 100%|██████████| 29/29 [00:43<00:00,  1.49s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:21<00:00,  1.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        460        410      0.803      0.794       0.88      0.596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     79/100      2.84G      1.227      1.265      1.404         22        640: 100%|██████████| 29/29 [00:45<00:00,  1.58s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:26<00:00,  1.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        460        410       0.82        0.8      0.892      0.618\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     80/100      2.84G      1.195      1.166      1.371         29        640: 100%|██████████| 29/29 [01:25<00:00,  2.94s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:37<00:00,  2.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        460        410       0.84      0.809      0.896      0.619\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     81/100      2.84G       1.18       1.17       1.36         15        640: 100%|██████████| 29/29 [01:21<00:00,  2.80s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:35<00:00,  2.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        460        410      0.813      0.869      0.903      0.636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     82/100      2.84G      1.217      1.169      1.386         15        640: 100%|██████████| 29/29 [01:05<00:00,  2.26s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:27<00:00,  1.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        460        410      0.806      0.863      0.904      0.648\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     83/100      2.84G      1.137      1.147      1.322         18        640: 100%|██████████| 29/29 [01:07<00:00,  2.33s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:36<00:00,  2.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        460        410      0.872      0.794      0.907      0.648\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     84/100      2.84G       1.15      1.092      1.336         22        640: 100%|██████████| 29/29 [02:16<00:00,  4.72s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:18<00:00,  1.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        460        410      0.799      0.862      0.905      0.641\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     85/100      2.84G       1.18      1.206      1.355         37        640: 100%|██████████| 29/29 [00:55<00:00,  1.91s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:21<00:00,  1.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        460        410      0.846      0.829      0.909      0.665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     86/100      2.84G      1.179      1.144      1.365         27        640: 100%|██████████| 29/29 [01:37<00:00,  3.35s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:27<00:00,  1.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        460        410      0.865      0.849      0.915       0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     87/100      2.84G      1.168       1.14      1.327         24        640: 100%|██████████| 29/29 [01:46<00:00,  3.67s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 15/15 [00:30<00:00,  2.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        460        410      0.815      0.857       0.91      0.655\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     88/100      2.84G      1.161      1.083       1.34         24        640:  48%|████▊     | 14/29 [00:45<00:49,  3.28s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m model\u001b[38;5;241m=\u001b[39mYOLO(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124myolo11n.pt\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m results\u001b[38;5;241m=\u001b[39m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata.yaml\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mimgsz\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m640\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Huấn luyện mô hình với dữ liệu tùy chỉnh\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\ultralytics\\engine\\model.py:810\u001b[0m, in \u001b[0;36mModel.train\u001b[1;34m(self, trainer, **kwargs)\u001b[0m\n\u001b[0;32m    807\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mmodel\n\u001b[0;32m    809\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mhub_session \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msession  \u001b[38;5;66;03m# attach optional HUB session\u001b[39;00m\n\u001b[1;32m--> 810\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    811\u001b[0m \u001b[38;5;66;03m# Update model and cfg after training\u001b[39;00m\n\u001b[0;32m    812\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m RANK \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m}:\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\ultralytics\\engine\\trainer.py:208\u001b[0m, in \u001b[0;36mBaseTrainer.train\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    205\u001b[0m         ddp_cleanup(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mstr\u001b[39m(file))\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 208\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mworld_size\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\ultralytics\\engine\\trainer.py:381\u001b[0m, in \u001b[0;36mBaseTrainer._do_train\u001b[1;34m(self, world_size)\u001b[0m\n\u001b[0;32m    379\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m autocast(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mamp):\n\u001b[0;32m    380\u001b[0m     batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpreprocess_batch(batch)\n\u001b[1;32m--> 381\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss_items \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    382\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m RANK \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    383\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m world_size\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\ultralytics\\nn\\tasks.py:113\u001b[0m, in \u001b[0;36mBaseModel.forward\u001b[1;34m(self, x, *args, **kwargs)\u001b[0m\n\u001b[0;32m     99\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    100\u001b[0m \u001b[38;5;124;03mPerform forward pass of the model for either training or inference.\u001b[39;00m\n\u001b[0;32m    101\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    110\u001b[0m \u001b[38;5;124;03m    (torch.Tensor): Loss if x is a dict (training), or network predictions (inference).\u001b[39;00m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mdict\u001b[39m):  \u001b[38;5;66;03m# for cases of training and validating while training.\u001b[39;00m\n\u001b[1;32m--> 113\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict(x, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\ultralytics\\nn\\tasks.py:291\u001b[0m, in \u001b[0;36mBaseModel.loss\u001b[1;34m(self, batch, preds)\u001b[0m\n\u001b[0;32m    288\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcriterion\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    289\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcriterion \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minit_criterion()\n\u001b[1;32m--> 291\u001b[0m preds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mimg\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m preds \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m preds\n\u001b[0;32m    292\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcriterion(preds, batch)\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\ultralytics\\nn\\tasks.py:114\u001b[0m, in \u001b[0;36mBaseModel.forward\u001b[1;34m(self, x, *args, **kwargs)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mdict\u001b[39m):  \u001b[38;5;66;03m# for cases of training and validating while training.\u001b[39;00m\n\u001b[0;32m    113\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss(x, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\ultralytics\\nn\\tasks.py:132\u001b[0m, in \u001b[0;36mBaseModel.predict\u001b[1;34m(self, x, profile, visualize, augment, embed)\u001b[0m\n\u001b[0;32m    130\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m augment:\n\u001b[0;32m    131\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_predict_augment(x)\n\u001b[1;32m--> 132\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predict_once\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprofile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvisualize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membed\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\ultralytics\\nn\\tasks.py:153\u001b[0m, in \u001b[0;36mBaseModel._predict_once\u001b[1;34m(self, x, profile, visualize, embed)\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m profile:\n\u001b[0;32m    152\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_profile_one_layer(m, x, dt)\n\u001b[1;32m--> 153\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# run\u001b[39;00m\n\u001b[0;32m    154\u001b[0m y\u001b[38;5;241m.\u001b[39mappend(x \u001b[38;5;28;01mif\u001b[39;00m m\u001b[38;5;241m.\u001b[39mi \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)  \u001b[38;5;66;03m# save output\u001b[39;00m\n\u001b[0;32m    155\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m visualize:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\ultralytics\\nn\\modules\\block.py:1043\u001b[0m, in \u001b[0;36mC2PSA.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m   1041\u001b[0m a, b \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcv1(x)\u001b[38;5;241m.\u001b[39msplit((\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mc, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mc), dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m   1042\u001b[0m b \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mm(b)\n\u001b[1;32m-> 1043\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcv2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\ultralytics\\nn\\modules\\conv.py:51\u001b[0m, in \u001b[0;36mConv.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m     50\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Apply convolution, batch normalization and activation to input tensor.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 51\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mact(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\batchnorm.py:193\u001b[0m, in \u001b[0;36m_BatchNorm.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    186\u001b[0m     bn_training \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunning_mean \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunning_var \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    188\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    189\u001b[0m \u001b[38;5;124;03mBuffers are only updated if they are to be tracked and we are in training mode. Thus they only need to be\u001b[39;00m\n\u001b[0;32m    190\u001b[0m \u001b[38;5;124;03mpassed when the update should occur (i.e. in training mode when they are tracked), or when buffer stats are\u001b[39;00m\n\u001b[0;32m    191\u001b[0m \u001b[38;5;124;03mused for normalization (i.e. in eval mode when buffers are not None).\u001b[39;00m\n\u001b[0;32m    192\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m--> 193\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    194\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    195\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# If buffers are not to be tracked, ensure that they won't be updated\u001b[39;49;00m\n\u001b[0;32m    196\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunning_mean\u001b[49m\n\u001b[0;32m    197\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrack_running_stats\u001b[49m\n\u001b[0;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    199\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunning_var\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrack_running_stats\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    200\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    201\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    202\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbn_training\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    203\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexponential_average_factor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    204\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    205\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\functional.py:2822\u001b[0m, in \u001b[0;36mbatch_norm\u001b[1;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[0;32m   2819\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m training:\n\u001b[0;32m   2820\u001b[0m     _verify_batch_size(\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize())\n\u001b[1;32m-> 2822\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2823\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2824\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2825\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2826\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrunning_mean\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2827\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrunning_var\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2828\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2829\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmomentum\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2830\u001b[0m \u001b[43m    \u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2831\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackends\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcudnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menabled\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2832\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model=YOLO('yolo11n.pt')\n",
    "results=model.train(data=\"data.yaml\",epochs=100,imgsz=640)  # Huấn luyện mô hình với dữ liệu tùy chỉnh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca3930a",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:\\\\Users\\\\ADMIN\\\\Desktop\\\\DEEP LEARNING MATERIAL\\\\ObjectDetection\\\\runs\\\\detect\\\\train2\\\\weights\\\\last.pt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01multralytics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m YOLO\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Tải mô hình YOLO đã huấn luyện sẵn\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m model3 \u001b[38;5;241m=\u001b[39m \u001b[43mYOLO\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mC:\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mUsers\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mADMIN\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mDesktop\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mDEEP LEARNING MATERIAL\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mObjectDetection\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mruns\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mdetect\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mtrain2\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mweights\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mlast.pt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Đọc ảnh vào\u001b[39;00m\n\u001b[0;32m      8\u001b[0m image_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFire.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\ultralytics\\models\\yolo\\model.py:23\u001b[0m, in \u001b[0;36mYOLO.__init__\u001b[1;34m(self, model, task, verbose)\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m \u001b[38;5;241m=\u001b[39m new_instance\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     22\u001b[0m     \u001b[38;5;66;03m# Continue with default YOLO initialization\u001b[39;00m\n\u001b[1;32m---> 23\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\ultralytics\\engine\\model.py:148\u001b[0m, in \u001b[0;36mModel.__init__\u001b[1;34m(self, model, task, verbose)\u001b[0m\n\u001b[0;32m    146\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_new(model, task\u001b[38;5;241m=\u001b[39mtask, verbose\u001b[38;5;241m=\u001b[39mverbose)\n\u001b[0;32m    147\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 148\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    150\u001b[0m \u001b[38;5;66;03m# Delete super().training for accessing self.model.training\u001b[39;00m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\ultralytics\\engine\\model.py:291\u001b[0m, in \u001b[0;36mModel._load\u001b[1;34m(self, weights, task)\u001b[0m\n\u001b[0;32m    288\u001b[0m weights \u001b[38;5;241m=\u001b[39m checks\u001b[38;5;241m.\u001b[39mcheck_model_file_from_stem(weights)  \u001b[38;5;66;03m# add suffix, i.e. yolo11n -> yolo11n.pt\u001b[39;00m\n\u001b[0;32m    290\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m Path(weights)\u001b[38;5;241m.\u001b[39msuffix \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 291\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mckpt \u001b[38;5;241m=\u001b[39m \u001b[43mattempt_load_one_weight\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweights\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    292\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtask\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    293\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moverrides \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39margs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset_ckpt_args(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39margs)\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\ultralytics\\nn\\tasks.py:900\u001b[0m, in \u001b[0;36mattempt_load_one_weight\u001b[1;34m(weight, device, inplace, fuse)\u001b[0m\n\u001b[0;32m    898\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mattempt_load_one_weight\u001b[39m(weight, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, fuse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m    899\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Loads a single model weights.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 900\u001b[0m     ckpt, weight \u001b[38;5;241m=\u001b[39m \u001b[43mtorch_safe_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# load ckpt\u001b[39;00m\n\u001b[0;32m    901\u001b[0m     args \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mDEFAULT_CFG_DICT, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m(ckpt\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_args\u001b[39m\u001b[38;5;124m\"\u001b[39m, {}))}  \u001b[38;5;66;03m# combine model and default args, preferring model args\u001b[39;00m\n\u001b[0;32m    902\u001b[0m     model \u001b[38;5;241m=\u001b[39m (ckpt\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mema\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m ckpt[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m])\u001b[38;5;241m.\u001b[39mto(device)\u001b[38;5;241m.\u001b[39mfloat()  \u001b[38;5;66;03m# FP32 model\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\ultralytics\\nn\\tasks.py:827\u001b[0m, in \u001b[0;36mtorch_safe_load\u001b[1;34m(weight, safe_only)\u001b[0m\n\u001b[0;32m    825\u001b[0m                 ckpt \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(f, pickle_module\u001b[38;5;241m=\u001b[39msafe_pickle)\n\u001b[0;32m    826\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 827\u001b[0m             ckpt \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcpu\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    829\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# e.name is missing module name\u001b[39;00m\n\u001b[0;32m    830\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m e\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodels\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\ultralytics\\utils\\patches.py:86\u001b[0m, in \u001b[0;36mtorch_load\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m TORCH_1_13 \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweights_only\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m kwargs:\n\u001b[0;32m     84\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweights_only\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m---> 86\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_torch_load\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\serialization.py:1425\u001b[0m, in \u001b[0;36mload\u001b[1;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[0;32m   1422\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m   1423\u001b[0m     pickle_load_args[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1425\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_file_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[0;32m   1426\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[0;32m   1427\u001b[0m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[0;32m   1428\u001b[0m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[0;32m   1429\u001b[0m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[0;32m   1430\u001b[0m         orig_position \u001b[38;5;241m=\u001b[39m opened_file\u001b[38;5;241m.\u001b[39mtell()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\serialization.py:751\u001b[0m, in \u001b[0;36m_open_file_like\u001b[1;34m(name_or_buffer, mode)\u001b[0m\n\u001b[0;32m    749\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[0;32m    750\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[1;32m--> 751\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    752\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    753\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\serialization.py:732\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[1;34m(self, name, mode)\u001b[0m\n\u001b[0;32m    731\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, mode):\n\u001b[1;32m--> 732\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mopen\u001b[39m(name, mode))\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:\\\\Users\\\\ADMIN\\\\Desktop\\\\DEEP LEARNING MATERIAL\\\\ObjectDetection\\\\runs\\\\detect\\\\train2\\\\weights\\\\last.pt'"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Tải mô hình YOLO đã huấn luyện sẵn\n",
    "model3 = YOLO(r'C:\\Users\\ADMIN\\Desktop\\DEEP LEARNING MATERIAL\\ObjectDetection\\runs\\detect\\train7\\weights\\last.pt')\n",
    "\n",
    "# Đọc ảnh vào\n",
    "image_path = 'Fire.jpg'\n",
    "image = cv2.imread(image_path)\n",
    "\n",
    "# Resize ảnh về kích thước mong muốn (ví dụ: 640x640)\n",
    "resized_image = cv2.resize(image, (640, 640))\n",
    "\n",
    "# Dự đoán trên ảnh đã thay đổi kích thước\n",
    "results = model3.predict(resized_image, show=True)  # predict on resized image\n",
    "\n",
    "# Chờ cho đến khi bạn nhấn một phím và sau đó đóng cửa sổ\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()  # Đóng tất cả cửa sổ OpenCV"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
