import streamlit as st
from PIL import Image
from ultralytics import YOLO
import cv2  # Import OpenCV to handle color conversion
import pandas as pd
import tempfile
import os
# Táº£i mÃ´ hÃ¬nh YOLOv11 Ä‘Ã£ huáº¥n luyá»‡n cá»§a báº¡n
model_path = r'C:\Users\ADMIN\Desktop\DEEP LEARNING MATERIAL\ObjectDetection\runs\detect\train7\weights\last.pt'
model = YOLO(model_path)  # Táº£i mÃ´ hÃ¬nh Ä‘Ã£ huáº¥n luyá»‡n tá»« tá»‡p .pt

# TiÃªu Ä‘á» trang web
st.title("á»¨ng Dá»¥ng Nháº­n Diá»‡n Há»a Hoáº¡n (Hoáº·c cÃ¡c váº­t dá»¥ng khÃ¡c (nhÆ° diá»‡n thoáº¡i ,laptop ,.....)) Tá»« áº¢nh VÃ  Video Táº£i LÃªn ğŸ”¥")

# HÆ°á»›ng dáº«n cho ngÆ°á»i dÃ¹ng
st.markdown("""
ChÃ o má»«ng báº¡n Ä‘áº¿n vá»›i á»©ng dá»¥ng nháº­n diá»‡n há»a hoáº¡n! 
Vui lÃ²ng táº£i lÃªn má»™t bá»©c áº£nh hoáº·c video tá»« mÃ¡y tÃ­nh cá»§a báº¡n, vÃ  mÃ´ hÃ¬nh sáº½ giÃºp báº¡n nháº­n diá»‡n xem trong áº£nh cÃ³ há»a hoáº¡n  hay khÃ´ng 
Hoáº·c cÃ¡c váº­t dá»¥ng khÃ¡c (nhÆ° diá»‡n thoáº¡i ,laptop ,.....)
""")
# ThÃªm má»™t nÃºt Ä‘á»ƒ chá»n loáº¡i tá»‡p (áº¢nh hoáº·c Video)
file_type = st.radio("Chá»n loáº¡i tá»‡p báº¡n muá»‘n táº£i lÃªn:", ('HÃ¬nh áº£nh', 'Video'))
if file_type == 'HÃ¬nh áº£nh':

    # Pháº§n táº£i áº£nh lÃªn
    uploaded_file = st.file_uploader("Táº£i lÃªn áº£nh Ä‘á»ƒ nháº­n diá»‡n", type=["jpg", "png", "jpeg"])

    if uploaded_file is not None:
        # Má»Ÿ áº£nh vÃ  hiá»ƒn thá»‹ trÃªn web
        image = Image.open(uploaded_file).convert('RGB')  # Chuyá»ƒn Ä‘á»•i áº£nh sang RGB Ä‘á»ƒ Ä‘áº£m báº£o mÃ u sáº¯c chÃ­nh xÃ¡c
        # st.image(image, caption="áº¢nh táº£i lÃªn", use_container_width=True)

        # Tiáº¿n hÃ nh nháº­n diá»‡n Ä‘á»‘i tÆ°á»£ng trÃªn áº£nh
        results = model(image)  # Sá»­ dá»¥ng mÃ´ hÃ¬nh Ä‘á»ƒ nháº­n diá»‡n trÃªn áº£nh

        # Plot results image
        im_bgr = results[0].plot()  # BGR-order numpy array
        im_rgb = Image.fromarray(im_bgr[..., ::-1])  # Chuyá»ƒn Ä‘á»•i tá»« BGR sang RGB vÃ  tá»« NumPy array sang PIL image

        # Hiá»ƒn thá»‹ áº£nh Ä‘Ã£ váº½ bounding box lÃªn
        # st.image(im_rgb, caption="Káº¿t quáº£ nháº­n diá»‡n vá»›i bounding box", use_container_width=True)

        # Láº¥y cÃ¡c thÃ´ng tin dá»± Ä‘oÃ¡n
        boxes = results[0].boxes  # Láº¥y bounding boxes
        names = [results[0].names[int(cls)] for cls in boxes.cls.int()]  # Class name for each box
        confidences = boxes.conf.cpu().numpy()  # Confidence score of each box
        coordinates = boxes.xywh.cpu().numpy()  # Tá»a Ä‘á»™ cá»§a bounding box

        # Táº¡o má»™t DataFrame Ä‘á»ƒ hiá»ƒn thá»‹ thÃ´ng tin dÆ°á»›i dáº¡ng báº£ng
        detection_data = {
            "Detection": [i + 1 for i in range(len(names))],
            "Class": names,
            "Confidence (%)": [confidence * 100 for confidence in confidences],
            "Coordinates (x_center, y_center, width, height)": [str(coord) for coord in coordinates]
        }
        
        detection_df = pd.DataFrame(detection_data)  # Táº¡o báº£ng tá»« dá»¯ liá»‡u
        # Hiá»ƒn thá»‹ báº£ng vá»›i thÃ´ng tin vá» cÃ¡c Ä‘á»‘i tÆ°á»£ng Ä‘Ã£ nháº­n diá»‡n
        st.subheader("ThÃ´ng Tin Nháº­n Diá»‡n")
        st.dataframe(detection_df.style.format({
            "Confidence (%)": "{:.2f}",
        }).set_properties(**{'text-align': 'center'}), width=1500)  # Äiá»u chá»‰nh chiá»u rá»™ng báº£ng vÃ  cÄƒn giá»¯a vÄƒn báº£n

        # Hiá»ƒn thá»‹ áº£nh gá»‘c vÃ  áº£nh Ä‘Ã£ nháº­n diá»‡n á»Ÿ 2 cá»™t riÃªng biá»‡t
        col1, col2 = st.columns([1, 1])
        
        with col1:
            st.subheader("áº¢nh Gá»‘c")
            st.image(image, caption="áº¢nh gá»‘c", use_container_width=True)

        with col2:
            st.subheader("áº¢nh ÄÃ£ Nháº­n Diá»‡n")
            st.image(im_rgb, caption="Káº¿t quáº£ nháº­n diá»‡n vá»›i bounding box", use_container_width=True)

        # Náº¿u phÃ¡t hiá»‡n "fire", hiá»ƒn thá»‹ thÃªm thÃ´ng bÃ¡o
        if 'fire' in names:
            st.success("PhÃ¡t hiá»‡n há»a hoáº¡n trong áº£nh!")
        else:
            st.warning("KhÃ´ng phÃ¡t hiá»‡n há»a hoáº¡n trong áº£nh.")
elif file_type == 'Video':
    model = YOLO("yolo11n.pt")  # Táº£i mÃ´ hÃ¬nh Ä‘Ã£ huáº¥n luyá»‡n tá»« tá»‡p .pt
    # Pháº§n táº£i video lÃªn
    uploaded_video = st.file_uploader("Táº£i lÃªn video Ä‘á»ƒ nháº­n diá»‡n", type=["mp4", "avi", "mov"])

    if uploaded_video is not None:
        # Táº¡o tá»‡p táº¡m thá»i Ä‘á»ƒ lÆ°u video
        with tempfile.NamedTemporaryFile(delete=False, suffix=".mp4") as tmp_file:
            tmp_file.write(uploaded_video.read())
            tmp_file_path = tmp_file.name

        # Äá»c video vÃ  hiá»ƒn thá»‹ cÃ¡c frame
        video = cv2.VideoCapture(tmp_file_path)

        stframe = st.empty()  # Táº¡o má»™t Ã´ trá»‘ng Ä‘á»ƒ hiá»ƒn thá»‹ video frame by frame

        # Táº¡o tá»‡p video Ä‘Ã£ nháº­n diá»‡n
        output_path = "output_video.mp4"
        fourcc = cv2.VideoWriter_fourcc(*"mp4v")  # Chá»n codec
        fps = video.get(cv2.CAP_PROP_FPS)
        width = int(video.get(cv2.CAP_PROP_FRAME_WIDTH))
        height = int(video.get(cv2.CAP_PROP_FRAME_HEIGHT))
        out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))

        # Äá»c video vÃ  xá»­ lÃ½ tá»«ng frame
        while video.isOpened():
            ret, frame = video.read()
            if not ret:
                break
            
            # Tiáº¿n hÃ nh nháº­n diá»‡n Ä‘á»‘i tÆ°á»£ng trÃªn má»—i frame
            results = model(frame)  # Sá»­ dá»¥ng mÃ´ hÃ¬nh Ä‘á»ƒ nháº­n diá»‡n trÃªn frame

            # Váº½ cÃ¡c bounding box lÃªn frame
            im_bgr = results[0].plot()  # BGR-order numpy array
            im_rgb = cv2.cvtColor(im_bgr, cv2.COLOR_BGR2RGB)  # Chuyá»ƒn Ä‘á»•i tá»« BGR sang RGB

            # Ghi láº¡i frame Ä‘Ã£ nháº­n diá»‡n vÃ o tá»‡p video
            out.write(im_bgr)  # Ghi frame vÃ o video

            # Hiá»ƒn thá»‹ frame Ä‘Ã£ nháº­n diá»‡n
            stframe.image(im_rgb, channels="RGB", use_container_width=True)

        # Giáº£i phÃ³ng video sau khi hoÃ n táº¥t
        video.release()
        out.release()

        # XÃ³a tá»‡p video táº¡m thá»i sau khi xá»­ lÃ½ xong
        os.remove(tmp_file_path)

        # Sau khi video Ä‘Ã£ xá»­ lÃ½ xong, hiá»ƒn thá»‹ video Ä‘Ã£ nháº­n diá»‡n trÃªn Streamlit
        st.subheader("Video ÄÃ£ Nháº­n Diá»‡n")
        

        # ThÃªm nÃºt "LÆ°u Video"
        if st.button("LÆ°u Video ÄÃ£ Nháº­n Diá»‡n"):
            # Cung cáº¥p video Ä‘Ã£ nháº­n diá»‡n Ä‘á»ƒ táº£i xuá»‘ng
            with open(output_path, "rb") as f:
                video_file = f.read()
            st.download_button(
                label="Táº£i video Ä‘Ã£ nháº­n diá»‡n",
                data=video_file,
                file_name="output_video.mp4",
                mime="video/mp4"
            )

        # XÃ³a tá»‡p video Ä‘Ã£ nháº­n diá»‡n sau khi phÃ¡t trÃªn web
        os.remove(output_path)